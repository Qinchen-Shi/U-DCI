{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util import load_data, load_graph\n",
    "from models.udci import U_DCI\n",
    "from models.clf_model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def finetune(config_udci, config_emb, model_pretrain, device, test_graph, feats_num, attention):\n",
    "    model = Classifier(config_udci['emb_module'], config_udci['hidden_dim'], config_udci['final_dropout'], config_emb, attention, device).to(device)\n",
    "    # emb_module, hidden_dim, final_dropout, config_emb\n",
    "    # replace the encoder in joint model with the pre-trained encoder，把外面训练好的CDI导进来，这个视角encoder吗\n",
    "    pretrained_dict = model_pretrain.state_dict()   # state_dict()是pytorch里调用所有参数信息的函数，这里是把DCI的参数信息存起来\n",
    "    model_dict = model.state_dict() #这里就是吧Classifier的参数信息存起来\n",
    "    pretrained_dict =  {k: v for k, v in pretrained_dict.items() if k in model_dict}    # 只留下Classifier里有的字段的DCI的参数信息，为了防止下一步错叭\n",
    "    model_dict.update(pretrained_dict)  # 这两步就是把Classifier的参数信息更新成DCI的参数信息\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), config_udci['lr'])  # 优化器的意思应该是反向传播的那个，不要纠结细节上次学过了虽然我知道你忘了\n",
    "    \n",
    "    criterion_tune = nn.BCEWithLogitsLoss() # 二分类的交叉熵损失函数\n",
    "\n",
    "    res = []\n",
    "    train_idx = test_graph[2]\n",
    "    node_train = test_graph[-1][train_idx, 0].astype('int')\n",
    "    label_train = torch.FloatTensor(test_graph[-1][train_idx, 1]).to(device)\n",
    "    # progress_bar2 = tqdm(total = config_udci['finetune_epochs'])\n",
    "    for i in range(1, config_udci['finetune_epochs']+1):  # 这一段应该就是在训练\n",
    "        model.train()\n",
    "        output = model(test_graph[0], test_graph[1])\n",
    "        loss = criterion_tune(output[node_train], torch.reshape(label_train, (-1, 1)))\n",
    "        # print(f'Epoch: {i} | Loss: {loss}')\n",
    "        \n",
    "        #backprop\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # progress_bar2.set_description(f'Epoch: {i}/{config_udci[\"finetune_epochs\"]}')\n",
    "        # progress_bar2.update()\n",
    "        \n",
    "        # testing\n",
    "        model.eval()    # 设成eval模式\n",
    "        auc = evaluate(model, test_graph)\n",
    "        res.append(auc)\n",
    "\n",
    "    return np.max(res)  # 返回最大的auc\n",
    "\n",
    "\n",
    "def evaluate(model, test_graph):\n",
    "    output = model(test_graph[0], test_graph[1])    #预测结果，其中0和1分别是adj和features，顺序记得确认一下\n",
    "    pred = sig(output.detach().cpu())   # 用激活函数压缩一下然后结果传到cpu上\n",
    "    test_idx = test_graph[3]    # 这个idx具体指什么要看model，我猜是abnormal data的idx\n",
    "    \n",
    "    labels = test_graph[-1] # 那么labels我猜就是abnormal data的label\n",
    "    pred = pred[labels[test_idx, 0].astype('int')].numpy()  # 不知道了这里回头再来看吧\n",
    "    target = labels[test_idx, 1]\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, _ = metrics.roc_curve(target, pred, pos_label=1)\n",
    "    auc = metrics.auc(false_positive_rate, true_positive_rate)  # auc越接近1越好\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_udci(trial):\n",
    "    nhid = trial.suggest_categorical('nhid', [8,16,32,64])\n",
    "    out = trial.suggest_categorical('out', [8,16,32,64])\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step=0.1)\n",
    "\n",
    "    \n",
    "    config_udci = {\n",
    "    'dataset': 'wiki',                      # name of dataset\n",
    "    'device': 0,                            # which gpu to use if any\n",
    "    'epochs': 100,                          # number of epochs in pre-training stage\n",
    "    'num_cluster': 20,                      # number of clusters in pre-training stage\n",
    "    'recluster_interval': 20,               # recluster interval in pre-training stage\n",
    "    'finetune_epochs': 200,                 # number of epochs in finetune stage\n",
    "    'num_folds': 10,                        # number of folds in cross validation of finetune stage\n",
    "    'final_dropout': 0.5,                   # dropout rate used in finetune stage\n",
    "    'lr': 0.005,                            # learning rate used in optimizer\n",
    "    'hidden_dim': 16,                       # number of hidden dims, used in Discriminator, must equal out dimension of confit_emb\n",
    "    'training_scheme': 'decoupled',         # 'decoupled' or 'joint'\n",
    "    'attention_scheme': False,              # True or False\n",
    "    'emb_module': 'GCN'                   # 'U_GCN', 'GIN', 'GCN', 'GraphSAGE', 'GAT'\n",
    "}\n",
    "\n",
    "\n",
    "    #U_GCN\n",
    "    if config_udci['emb_module'] == 'U_GCN':\n",
    "        config_emb = {\n",
    "            'out_features': 16,     # number of feature dims generated by one attention head, used in GraphAttention\n",
    "            'alpha': 0.2,           # slope of leakyReLU, used in GraphAttention\n",
    "            'final_features': 16,   # number of feature dims integrated out of all attention heads, used in GraphAttention\n",
    "            'dropout': 0,         # customized dropout rate, used in GraphAttention & GAT \n",
    "            'nheads' : 8\n",
    "        }\n",
    "\n",
    "    # GIN\n",
    "    elif config_udci['emb_module'] == 'GIN':\n",
    "        config_emb = {\n",
    "            'num_layers': 2,        # default: 2\n",
    "            'num_mlp_layers': 2,    # default: 2\n",
    "            'hidden_dim': 16,       # default: 16\n",
    "            'neighbor_pooling_type': 'sum'\n",
    "        }\n",
    "\n",
    "    # GCN (未调优)\n",
    "    elif config_udci['emb_module'] == 'GCN':\n",
    "        config_emb = {\n",
    "            'nhid': nhid,         # default: 64\n",
    "            'out': out,          # default: 16\n",
    "            'dropout': dropout      # default: 0.1\n",
    "        }\n",
    "\n",
    "    # GraphSAGE\n",
    "    elif config_udci['emb_module'] == 'GraphSAGE':\n",
    "        config_emb = {\n",
    "            'nhid': 64,         # default: 64\n",
    "            'out': 16,          # default: 16\n",
    "            'dropout': 0      # default: 0.5\n",
    "        }\n",
    "\n",
    "    # GAT\n",
    "    elif config_udci['emb_module'] == 'GAT':\n",
    "        config_emb = {\n",
    "            'out_features': 64,         # default: 64\n",
    "            'final_features': 16,       # default: 16\n",
    "            'dropout': 0,               # default: 0.6\n",
    "            'alpha': 0.2,               # default: 0.2\n",
    "            'nheads' : 8                # default: 8\n",
    "        }\n",
    "\n",
    "    \n",
    "    setup_seed(0)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device('cpu')\n",
    "\n",
    "    edge_index, feats, split_idx, label, nb_nodes = load_data(config_udci['dataset'], config_udci['num_folds'], 0.8)\n",
    "    config_emb['input_dim'] = feats.shape[1]\n",
    "    config_udci['hidden_dim'] = config_emb['out']\n",
    "\n",
    "    kmeans = KMeans(n_clusters=config_udci['num_cluster'], random_state=0).fit(feats)\n",
    "    ss_label = kmeans.labels_\n",
    "    cluster_info = [list(np.where(ss_label==i)[0]) for i in range(config_udci['num_cluster'])]\n",
    "\n",
    "    idx = np.random.permutation(nb_nodes)\n",
    "    shuf_feats = feats[idx, :]\n",
    "\n",
    "    adj = load_graph(torch.LongTensor(edge_index), nb_nodes, config_udci['emb_module'], device)\n",
    "    feats = torch.FloatTensor(feats).to(device)\n",
    "    shuf_feats = torch.FloatTensor(shuf_feats).to(device)\n",
    "\n",
    "    # progress_bar = tqdm(total = config_udci['epochs'])\n",
    "    model_pretrain = U_DCI(config_udci['emb_module'], config_udci['hidden_dim'], config_emb, config_udci['attention_scheme'], device).to(device)\n",
    "    optimizer_train = optim.Adam(model_pretrain.parameters(), lr=config_udci['lr'])\n",
    "\n",
    "    store_loss = []\n",
    "\n",
    "    \n",
    "    for epoch in range(1, config_udci['epochs'] + 1):\n",
    "        model_pretrain.train()\n",
    "        loss_pretrain = model_pretrain(feats, shuf_feats, adj, None, None, None, cluster_info, config_udci['num_cluster'])\n",
    "\n",
    "        if optimizer_train is not None:\n",
    "            optimizer_train.zero_grad()\n",
    "            loss_pretrain.backward()         \n",
    "            optimizer_train.step()\n",
    "            store_loss.append(loss_pretrain.item())\n",
    "        else:\n",
    "            print(f'Optimizer is none. Current epoch: {epoch}')\n",
    "        # progress_bar.set_description(f'Epoch: {epoch}/{config_udci[\"epochs\"]} | Current loss: {loss_pretrain.item():.3f}')\n",
    "        # progress_bar.update()\n",
    "        \n",
    "        # re-clustering\n",
    "        if epoch % config_udci['recluster_interval'] == 0 and epoch < config_udci['epochs']:\n",
    "            model_pretrain.eval()\n",
    "            emb = model_pretrain.get_emb(feats, adj)\n",
    "            kmeans = KMeans(n_clusters=config_udci['num_cluster'], random_state=0).fit(emb.detach().cpu().numpy())\n",
    "            ss_label = kmeans.labels_\n",
    "            cluster_info = [list(np.where(ss_label==i)[0]) for i in range(config_udci['num_cluster'])]\n",
    "\n",
    "    # print(f'Pre-training Down!')\n",
    "\n",
    "    fold_idx = 1\n",
    "    every_fold_auc = []\n",
    "    for (train_idx, test_idx) in split_idx: # split_idx在load data的时候就生成了\n",
    "        test_graph = (feats, adj, train_idx, test_idx, label)\n",
    "        tmp_auc = finetune(config_udci, config_emb, model_pretrain, device, test_graph, config_emb['input_dim'], config_udci['attention_scheme'])\n",
    "        every_fold_auc.append(tmp_auc)\n",
    "        # print(f'AUC on the Fold {fold_idx}: {tmp_auc:.4f}')    # 会返回每种folder的auc，每个auc是模型优化后最好的auc（因为是max）\n",
    "        fold_idx += 1\n",
    "    # print(f'The averaged AUC score: {np.mean(every_fold_auc):.4f}')\n",
    "    # print(f'The std of AUC score: {np.std(every_fold_auc):.4f}')\n",
    "\n",
    "    return np.mean(every_fold_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-14 17:36:00,716] A new study created in memory with name: no-name-5d332db7-6763-4795-a583-b720c24f7a74\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:36:22,673] Trial 0 finished with value: 0.6613854774555061 and parameters: {'nhid': 16, 'out': 16, 'dropout': 0.2}. Best is trial 0 with value: 0.6613854774555061.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:36:57,650] Trial 1 finished with value: 0.6743750544377667 and parameters: {'nhid': 64, 'out': 32, 'dropout': 0.0}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:37:29,849] Trial 2 finished with value: 0.6589720697964754 and parameters: {'nhid': 32, 'out': 32, 'dropout': 0.4}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:37:59,551] Trial 3 finished with value: 0.6227702290741224 and parameters: {'nhid': 8, 'out': 32, 'dropout': 0.0}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:38:26,673] Trial 4 finished with value: 0.6660990622187382 and parameters: {'nhid': 32, 'out': 16, 'dropout': 0.4}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:38:50,222] Trial 5 finished with value: 0.6236267166042447 and parameters: {'nhid': 8, 'out': 16, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:39:19,350] Trial 6 finished with value: 0.6227702290741224 and parameters: {'nhid': 8, 'out': 32, 'dropout': 0.0}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "[I 2023-08-14 17:39:46,521] Trial 7 finished with value: 0.670574572482072 and parameters: {'nhid': 32, 'out': 16, 'dropout': 0.2}. Best is trial 1 with value: 0.6743750544377667.\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the edge_index done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/wo22153/Library/Python/3.9/lib/python/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(function_udci, n_trials=100)\n",
    "best_params_udci = study.best_params\n",
    "best_eval_udci = study.best_value\n",
    "print('Best parameters: ', best_params_udci)\n",
    "print('Best evaluation: ', best_eval_udci)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
